{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import starepandas\n",
    "import geopandas\n",
    "import sqlalchemy\n",
    "import pyhdf\n",
    "import shapely\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_spatialite(dbapi_conn, connection_record):\n",
    "    dbapi_conn.enable_load_extension(True)\n",
    "    dbapi_conn.load_extension('mod_spatialite')\n",
    "\n",
    "db_path = 'wkb.sqlite' # Empty string for inmemory\n",
    "uri = 'sqlite:///{db_path}'.format(db_path=db_path)\n",
    "engine = sqlalchemy.create_engine(uri, echo=False)\n",
    "sqlalchemy.event.listen(engine, 'connect', load_spatialite)\n",
    "conn = engine.connect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = ['Buenos Aires', 'Brasilia', 'Santiago', \n",
    "          'Bogota', 'Caracas', 'Sao Paulo', 'Bridgetown']\n",
    "\n",
    "latitudes = [-34.58, -15.78, -33.45, 4.60, 10.48, -23.55, 13.1]\n",
    "longitudes = [-58.66, -47.91, -70.66, -74.08, -66.86, -46.63, -59.62]\n",
    "data =  {'name': names, \n",
    "         'latitude': latitudes, 'longitude': longitudes}\n",
    "\n",
    "cities = starepandas.STAREDataFrame(data)\n",
    "geom = geopandas.points_from_xy(cities.longitude, \n",
    "                                cities.latitude, crs='EPSG:4326')\n",
    "cities.set_geometry(geom, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cities = geopandas.io.sql._convert_to_ewkb(cities, 'geometry', 4326)\n",
    "cities.to_sql(name='cities', con=engine, if_exists='replace',)\n",
    "conn.execute(\"UPDATE cities SET geometry=GeomFromEWKB(geometry);\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countries = geopandas.read_file(geopandas.datasets.get_path('naturalearth_lowres'))\n",
    "countries = countries.sort_values(by='name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from shapely.ops import orient # version >=1.7a2\n",
    "geom = countries.geometry.apply(orient, args=(1,))\n",
    "countries = countries.set_geometry(geom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "countries = geopandas.io.sql._convert_to_ewkb(countries, 'geometry', 4326)\n",
    "countries.to_sql(name='countries', con=engine, if_exists='replace',)\n",
    "conn.execute(\"UPDATE countries SET geometry=GeomFromEWKB(geometry);\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Granule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = 'data/MYD05_L2.A2020060.1635.061.2020061153519.hdf'\n",
    "mod05 = starepandas.read_mod05(fname)\n",
    "mod05.to_sql(name='mod05', con=engine, if_exists='replace')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Granule cover"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_box(tile_name):\n",
    "    hdf = pyhdf.SD.SD(tile_name)\n",
    "    lat = hdf.select('Latitude').get()\n",
    "    lon = hdf.select('Longitude').get()\n",
    "    p1 = shapely.geometry.Point(lon[0][0], lat[0][0])\n",
    "    p2 = shapely.geometry.Point(lon[0][-1], lat[0][-1])\n",
    "    p3 = shapely.geometry.Point(lon[-1][-1], lat[-1][-1])\n",
    "    p4 = shapely.geometry.Point(lon[-1][0], lat[-1][0])    \n",
    "    pointList = [p1, p2, p3, p4, p1]\n",
    "    poly = shapely.geometry.Polygon(pointList)\n",
    "    return poly\n",
    "\n",
    "\n",
    "file_names = glob.glob('data/*.hdf')\n",
    "\n",
    "bounding_polys = []\n",
    "for file_name in file_names:\n",
    "    bounding_poly = get_box(file_name)\n",
    "    bounding_polys.append(bounding_poly)\n",
    "\n",
    "covers = starepandas.STAREDataFrame({'name': file_names, \n",
    "                                     'geometry': bounding_polys})\n",
    "\n",
    "covers = geopandas.io.sql._convert_to_ewkb(covers, 'geometry', 4326)\n",
    "covers.to_sql(name='covers', con=engine, if_exists='replace',)\n",
    "conn.execute(\"UPDATE covers SET geometry=GeomFromEWKB(geometry);\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyhdf.SD import SD\n",
    "import starepandas\n",
    "import numpy\n",
    "file_path = 'data/MOD05_L2.A2020254.1320.061.2020255013126.hdf'\n",
    "hdf = SD(file_path)\n",
    "metadata = starepandas.get_hdfeos_metadata(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['ArchiveMetadata', 'StructMetadata', 'CoreMetadata'])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([29.35669973, 25.94150104,  8.2344792 , 11.19473808]),\n",
       " array([-50.04725267, -26.57481897, -31.62360145, -52.77611565]))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gring_point = metadata['ArchiveMetadata']['ARCHIVEDMETADATA']['GPOLYGON']['GPOLYGONCONTAINER']['GRINGPOINT']\n",
    "gring_seq = numpy.array(eval(gring_point['GRINGPOINTSEQUENCENO']['VALUE'])[:], dtype=numpy.int)-1\n",
    "gring_lon = numpy.array(eval(metadata['ArchiveMetadata']['ARCHIVEDMETADATA']['GPOLYGON']['GPOLYGONCONTAINER']['GRINGPOINT']['GRINGPOINTLONGITUDE']['VALUE'])[:], dtype=numpy.double)\n",
    "gring_lat = numpy.array(eval(metadata['ArchiveMetadata']['ARCHIVEDMETADATA']['GPOLYGON']['GPOLYGONCONTAINER']['GRINGPOINT']['GRINGPOINTLATITUDE']['VALUE'])[:], dtype=numpy.double)\n",
    "gring_lat[gring_seq],gring_lon[gring_seq]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'(29.3566997264978, 25.9415010426761, 8.23447920000618, 11.1947380805796)'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata['ArchiveMetadata']['ARCHIVEDMETADATA']['GPOLYGON']['GPOLYGONCONTAINER']['GRINGPOINT']['GRINGPOINTLATITUDE']['VALUE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['SwathStructure', 'GridStructure', 'PointStructure'])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata['ArchiveMetadata'].keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert to spatialite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "conn.execute(\"SELECT InitSpatialMetaData(1, 'WGS84');\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "conn.execute(\"SELECT RecoverGeometryColumn('cities', 'geometry', 4326, 'POINT');\")\n",
    "conn.execute(\"UPDATE countries SET geometry=CastToMultiPolygon(geometry)\");\n",
    "conn.execute(\"SELECT RecoverGeometryColumn('countries', 'geometry', 4326, 'MULTIPOLYGON');\")\n",
    "conn.execute(\"SELECT RecoverGeometryColumn('covers', 'geometry', 4326, 'POLYGON');\")\n",
    "\n",
    "conn.execute(\"SELECT CreateSpatialIndex('countries', 'geometry');\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "conn.execute(\"SELECT RecoverGeometryColumn('countries', 'geometry', 4326, 'POLYGON');\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
